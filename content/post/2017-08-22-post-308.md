---
title: なぜWebサイトをHTTPSに対応させなければならないのか
author: user
type: post
date: 2017-08-22T03:34:05+00:00
url: /poem/308/
amazonS3_cache:
  - 'a:3:{s:56:"//www.atmarkit.co.jp/ait/articles/1708/16/news012_2.html";a:1:{s:9:"timestamp";i:1503372830;}s:58:"//images-fe.ssl-images-amazon.com/images/I/51qrqQp2cQL.jpg";a:1:{s:9:"timestamp";i:1503372967;}s:66:"//images-fe.ssl-images-amazon.com/images/I/51qrqQp2cQL._SL160_.jpg";a:1:{s:9:"timestamp";i:1503373005;}}'
update_level:
  - high
categories:
  - poem

---
GoogleのChromeがChrome62から入力欄を持つ非HTTPSのサイト全てに警告を出すということがニュースになっていたので、その経緯について簡単に書いておきます。

ただ、これから書くことは昨年のSymantecの子会社による不正な証明書の発行に関するニュースや記事を追っていた際についでに拾った情報をまとめて推測してみたらこういう話になったというだけで、その関係で一部情報元が確認できなかった情報もありますし、Googleがはっきりとこうだと言っているわけでもありませんので読み物として読んでみてください。
  
業界全体の流れとしてそういう方向に向かっているというだけの話です。

さて、事の発端はNSAによる市民の監視プロジェクト、PRISM計画の存在を明るみにしたスノーデン・ショックです。
  
PRISM計画の詳細については省きますが、NSAがMicrosoftやGoogleなどに情報を収集できるバックドアを仕掛け一般人をも含め監視していたというこの計画では、そういった各企業に仕掛けたバックドアから得た情報の他に海底ケーブルや基地局からも情報を収集し分析していました。

なお、このPRISM計画の中で直接名指しされた企業はNSAへの協力をハッキリとは認めてはいません。
  
Googleはこの事件の発覚前から透明性レポートというものを出しており、政府から要請のあった情報請求と実際に提供した件数などを公開していましたが、このPRISM計画に関係するものは含まれていなかったのではないかとされています。
  
また、Google以外の企業もこの事件の発覚以降、Googleの透明性レポートと同じようなものを定期的に公開するようになっています。

基本的にネットワークを流れる通信を盗聴した場合、その通信内容が暗号化されていれば具体的な通信の内容は確認できませんが、暗号化されていなければ確認することができます。
  
さて、問題はこの暗号化されていない通信の内容に含まれる情報です。
  
ここではWebの通信に限って話を進めますが、氏名や住所などの個人情報や、クレジットカード番号などが含まれていなければ通信は暗号化しなくともよいというのが一般的な考え方でした。

しかし、Webの通信には広告などのためにユーザーを識別できる情報や、閲覧しているサイトを見る直前のサイトの情報などのメタ情報が多く含まれています。
  
また、通信内容に個人情報が含まれていなかったとしても、通信しているユーザーが医療情報サイトを多数閲覧していれば本人か家族に健康に不安があるんだなと推測できますし、イスラム教の教えを説いているサイトを閲覧していればこの人はイスラム教に興味がある、または信者なんだと推測することができます。
  
実際には通信内容が暗号化されていても、ユーザーがどのドメイン名のWebサイトを閲覧しているかは分かります。

NSAはこういった通信内容に含まれるメタ情報を大量に収集して、ユーザーの人種や宗教、思想、年収、イデオロギーなどを分析するのに活用していました。
  
このことが明るみになってからアメリカのセキュリティ界隈では、例え個人情報などを収集していなくても、WebサイトをHTTPSに対応させユーザーを保護するべきだという声が大きくなっています。

Symantec子会社の不正証明書発行事件の際もそうでしたが、特にGoogleは<del datetime="2017-08-22T00:50:38+00:00">過激派</del>先進的なので、Chromeに今回の入力欄を持つ非HTTPSなサイトへの警告などの独自実装を取り入れてたり、検索エンジンで非HTTPSなサイトよりHTTPSのサイトを優遇していたりします。

Googleは将来的には全ての非HTTPSのサイトに対してChromeで警告を出したいと考えているようですので、今回の仕様の変更はそのためのステップの１つに過ぎないのかもしれません。
  
他のブラウザベンダーがこの動きに追従するかは不明ですが、アメリカのセキュリティ業界ではWebサイトは基本的にHTTPSに対応させるべきだという流れになっています。

つい先日、シカゴの有権者データがAWSのS3で公開状態になっていた件がニュースになっていましたが、[記事](https://threatpost.com/vendor-exposes-backup-of-chicago-voter-roll-via-aws-bucket/127538/)の中でデータの管理を請け負っていたElection Systems & SoftwareのWebサイトがHTTPSに対応していないことが指摘されており、特に企業サイトなどはHTTPSに対応していないことがセキュリティリスクだとして指摘されるようになる日も遠くないのかもしれません。

ここからは余談ですが、スノーデン・ショックで注目を浴びるようになったのがLet&#8217;sEncryptです。
  
もともとスノーデン・ショック以前から一部の研究者によってWebから大量のメタ情報を収集することにより個人の特定や分析が可能だということは指摘されていましたが、あまり現実的ではないと思われていました。

Let&#8217;sEncryptは全てのWebのトラフィックをHTTPSに置き換えることを目標にして立ち上がりましたが、当初はスポンサーも少なくルート認証局を持てずにいました。

しかし、スノーデン・ショックによって実際に国家規模のネットの監視が明るみになって以降、もともと設立時から携わっていたMozillaやEFFに加え、AkamaiやCiscoなどもスポンサーに加わりIdenTrustがLet&#8217;sEncryptの発行する証明書のルート認証局になることでいっきにその知名度を上げ、実際に証明書を発行できるようになっています。

他にも、つい最近の話になりますが、[2017年6月の＠ITセキュリティセミナー](http://www.atmarkit.co.jp/ait/articles/1708/16/news012_2.html)でサイバーセキュリティ研究開発センターの安藤類央氏が以下のように述べています。


>例えばFacebookは、どの『いいね！』ボタンを押したかというデータを基に、ユーザーの人種、性格、性的指向、政治的イデオロギー、配偶者や恋人の有無、薬物常用の有無を言い当てられるという。「メタデータは、その人の生活全てを確実に映し出す。十分な量のメタデータがあれば、コンテンツはいらない」というNSA元法律責任者の声や「私たちは、あなたが今どこにいるのかを知っている。これまで、どこにいたかを知っている。今、何を考えているのかも大体知っている」というGoogleのエリック・シュミット氏の声からもデータの持つ威力がうかがい知れるだろう。

